---
title: "Fall 2022 Galleria field infection data"
author: "Morgan Swoboda"
date: "2023-02-13"
output: github_document
---

# Package install and upload data sheet
```{r, eval = TRUE}

#install.packages("emmeans")
#install.packages("ggthemes")

library(ggplot2)
library(emmeans)
library(tidyr)
library(dplyr)
library(ggthemes)
library(RColorBrewer)

#import data
Fall22EPF <- read.csv("Fall 22 epf bioassay - Sheet1 (1).csv", )

#make treatments and varieties into factors
Fall22EPF$treatment = factor(Fall22EPF$treatment, levels = c("Control", "10Met", "10Bb"))
Fall22EPF$variety = factor(Fall22EPF$variety, levels = c("Cochise", "Armani"))
#Fall22EPF$num.dead = as.numeric(Fall22EPF$num.dead)
#Fall22EPF$num.pupae = as.numeric(Fall22EPF$num.pupae)
#Fall22EPF$total.out = as.numeric(Fall22EPF$total.out)
#Fall22EPF$num.met.infect = as.numeric(Fall22EPF$num.met.infect)
```

# Prelim data check
```{r, eval=TRUE}
#histogram of the distribution of number of metarhizium infected insects
hist(Fall22EPF$num.met.infect)

#need to make a histogram of the residuals?

#proportion of met infected
ggplot(data = Fall22EPF, aes(x = treatment, y = prop.met.inf, color = variety)) + geom_boxplot() + 
  ggtitle("Proportion of Metarhizium infection")

#number of met infected
ggplot(data = Fall22EPF, aes(x = treatment, y = prop.met.inf, color = variety)) + geom_boxplot() + 
  ggtitle("Number of Metarhizium infection")
#the same graph basically, but that makes sense?
```

# Stats for Metarhizium - ANOVA
## This is how I've analyzed all the previous data
### Do I use the number of met infection, or the proportions?
```{r,eval=TRUE}
attach(Fall22EPF)

##two way ANOVA
two.way.Met <- aov(perc.met.inf~treatment*variety)
summary(two.way.Met) #no signifcant differences, no interaction, change to one way model instead?
summary.lm(two.way.Met)

##one way anova
one.way.Met <- aov(perc.met.inf~treatment)
summary(one.way.Met) #not significant
summary.lm(one.way.Met)
plot(one.way.Met) #probably not normal based on QQ plot, looks like it's exponential?
shapiro.test(resid(one.way.Met)) #residuals NOT normal
fligner.test(prop.met.inf~treatment) #normal

#KW instead since it's not normal
##KW for met
MetF22KW <- kruskal.test(perc.met.inf~treatment)
print(MetF22KW) #not significant

#make some graphs
par(mfrow = c(1,2))
plot(treatment, num.met.infect, ylab = "number of met infected")
plot(treatment, perc.met.inf, ylab = "prop met infected")

#nice plot
met.inf.F22 <- ggplot(data = Fall22EPF, aes(x = treatment, y = perc.met.inf, fill = treatment)) + 
  geom_bar(stat = "summary", fun = "mean", position = "dodge", color = "black") + 
  scale_fill_manual(values=c("#B31B1B", "#ddd3c2", "#221f1b")) +
  geom_errorbar(stat = "summary", fun.data = "mean_se", aes(x=treatment), position = "dodge", width = 0.5) + 
  ylab("Percent of G. mellonella infected by M. anisopliae") + 
  theme_classic() + theme(text = element_text(size=15)) + 
  theme(legend.position = "none") + ggtitle("Fall 2022")

#centered the title and made an object
met.inf.F22 <- met.inf.F22 + theme(plot.title = element_text(hjust = 0.5))
met.inf.F22

```

# *Evertyhing below this was just to try it out - staying with anovas/non-parametric (ABOVE)*
# Try a different type of analysis? X is categorical, Y is discrete?

# Try a GLM?
## can use a GLM when the variance is not constant, and/or when the errors are not normally distributed
### Might consider using GLMs when the response variable is: count data expressed as proportions, count data that are not proportions, binary response variables, data on time to death where the varience increases faster than linearly with the mean
```{r, eval=TRUE}
names(Fall22EPF) 
#num.dead is the number of galleria counted as dead, num.pupae is the number that pupated, total.out
#is the sum of num.dead and num.pupae, num.met.infect is the number of galleria that exhibited
#Metarhizium infections

#look at main effect means
tapply(prop.met.inf, treatment, mean)
tapply(num.met.infect, treatment, mean)
tapply(prop.met.inf, variety, mean)

#check with error distribution works best with this data
library(MASS)
fit1 <- fitdistr(Fall22EPF$prop.met.inf, "normal")
fit2 <- fitdistr(Fall22EPF$num.met.infect, "Poisson")
fit3 <- fitdistr(Fall22EPF$prop.met.inf, "exponential")
fit4 <- fitdistr(Fall22EPF$num.met.infect, "negative binomial")

#check the AIC of the three error distributions
AIC(fit1, fit2, fit3, fit4) #the smaller the AIC, the better fit. 
#fit 1 and 3 have negative AICs?

#glm model of interactions between treatment and variety - Poisson error distribution
glmintmodel <- glm(num.met.infect ~ treatment * variety, poisson)
summary(glmintmodel) #no interaction

#histogram of the residuals - looks like negative binomial
ggplot(data = Fall22EPF, aes(x = glmintmodel$residuals)) +
    geom_histogram(fill = 'steelblue', color = 'black') +
    labs(title = 'Histogram of Residuals - Poisson', x = 'Residuals', y = 'Frequency')

#glm model of interactions between treatment and variety - negative binomial
#error distribution
glmintmodel2 <- glm.nb(num.met.infect ~ treatment * variety) 
#using glm.nb() - A modification of the system function glm() to include estimation of the 
#additional parameter, theta, for a Negative Binomial generalized linear model.
summary(glmintmodel2) #no interaction

#histogram of the residuals
ggplot(data = Fall22EPF, aes(x = glmintmodel2$residuals)) +
    geom_histogram(fill = 'steelblue', color = 'black') +
    labs(title = 'Histogram of Residuals - NB', x = 'Residuals', y = 'Frequency')

#R reports two forms of deviance – the null deviance and the residual deviance. The null deviance
#shows how well the response variable is predicted by a model that includes only the intercept
#(grand mean). It’s a measure of badness of fit–higher numbers indicate worse fit.  As a general
#rule of thumb, you should hope that your Residual deviance is not more than twice your degrees of
#freedom.

#The Akaike Information Criterion (AIC) provides a method for assessing the quality of your model 
#through comparison of related models.  It’s based on the Deviance, but penalizes you for making the
#model more complicated.  Much like adjusted R-squared, it’s intent is to prevent you from including
#irrelevant predictors. However, unlike adjusted R-squared, the number itself is not meaningful. If
#you have more than one similar candidate models (where all of the variables of the simpler model
#occur in the more complex models), then you should select the model that has the smallest AIC. So
#it’s useful for comparing models, but isn’t interpretable on its own.

# not including interaction term 
nointmodel <-  glm(num.met.infect ~ treatment, poisson)
summary(nointmodel)

#histogram of the residuals
ggplot(data = Fall22EPF, aes(x = nointmodel$residuals)) +
    geom_histogram(fill = 'steelblue', color = 'black') +
    labs(title = 'Histogram of Residuals - no interaction', x = 'Residuals', y = 'Frequency')

#see how the models compare to each other using an anova
anova(glmintmodel,glmintmodel2,nointmodel, test = "Chi") #not significantly different, so we're ok using the model2?
# Ashley suggested to keep the variety interaction even though it's not significant
#the model2 doesn't seem like a good fit

#try again without the last model
anova(glmintmodel,glmintmodel2, test = "Chi")

#install.packages("rcompanion") #this package is needed for the compareGLM function to compare model fits
library(rcompanion)
compareGLM(glmintmodel, glmintmodel2) #neg binomial still looks the best?

#not using this code below
#test the model that you think fits best with the Hosmer Lemeshow goodness of fit test.
# install.packages("ResourceSelection") #need this package for the hoslem.test() function.
#library(ResourceSelection)
#hoslem.test(Fall22EPF$num.met.infect, fitted(model2))
```

# Now that we know the Negative Binomial error distribution is probably the pest fit, analyze the data
```{r, eval=TRUE}
#Using a Chi Squared bc proportions
met.inf.anova <- anova(glmintmodel2, test = "Chisq") #running the chi sqaured test
met.inf.anova #no signficant differences
emmeans::emmeans(glmintmodel2, pairwise~treatment, type="response") #looking at mean comparisons, no signficant differences
```
# using the lmer for GLMM??
```{r, eval=TRUE}
install.packages("lme4")
library(lme4)
```

